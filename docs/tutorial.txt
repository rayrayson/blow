Tutorial
========

This short tutorial shows how to configure and run SGE cluster in the Amazon public cloud.

The cluster is made up of 5 nodes, as showed in the picture below. One node is defined as
the SGE *master* node, and the remaining 4 are defined as the SGE *workers* nodes.

To the *master* node are attached and mounted two EBS volumes. The first contains the application binaries and
is exported using the *Network File System* (NFS) with the path ``/soft``.

The second volume is used to share application data and is exported with a NFS sharing the with the path ``/scratch``.

.. image:: images/cluster.png
   :width: 600


It is assumed that you have a basic knowledge of the *SGE* resource manages workflow. A detailed explanation of *SGE* concepts
and commands is available at this link: http://gridscheduler.sourceforge.net/howto/howto.html



1. Download the *Blow* executable distribution
----------------------------------------------

The latest *Blow* executable distribution is available at `this link`_. Download and
save it somewhere on your machine.

If you are running a \*nix system (Linux, Mac OS X, etc.) grant the execute permission
to the downloaded *JAR* file, with the following command::

  # chmod +x blow.jar 
  
  

.. _`this link`: http://dl.dropbox.com/u/376524/blow/blow.jar


2. The configuration file
--------------------------------

Create a file named ``blow.conf`` with the content shown below. Save it in the same directory
where the ``blow.jar`` was downloaded. ::


  blow_simple_cluster {
    access-key = <replace with your AWS access key>
    secret-key = <replace with your AWS secret key>
    region-id = us-east-1
    zone-id = us-east-1b
    image-id = ami-e565ba8c		
    instance-type = t1.micro
    size = 5

    operations = [
      hostname
      { nfs { path: /soft }}
      { nfs { path: /scratch }}
      { sge { root: /soft/sge6 }}
    ]
  }


This configuration will deploy a cluster made up of 5 nodes. It uses the Amazon Linux AMI 2012.03 (x86_64) with ID ``ami-e565ba8c``.

It installs the SGE resource manager in the shared path ``/soft/sge6`` and a second shared path named ``/scratch`` is created.


3. Launch the cluster 
---------------------

The *Blow* command needs to be executed using the command line interface. It has the following syntax::

  blow.jar [blow options] [command name [command parameters] ]

If the *command name* is omitted it will run in the *interactive* mode, waiting for a command to be executed.

.. note::
  Windows users need to launch the *Blow* application with the *Java* interpreter. So the above syntax must be replaced 
  as follows::
  
    java -jar blow.jar [blow options] [command name [command parameters] ]
     

For the sake of this example start *Blow* in the interactive mode. Open a terminal window, 
move to the directory where the configuration file and the *Blow* executable have been saved and
specify the following command::

  # ./blow.jar
  
If a SSH key-pair cannot be found in the current directory or in the ``$HOME/.ssh/`` path,
it will prompt you to create a new key pair.
Answer ``y`` and press enter to proceed. 

When done you will get the *Blow* prompt as shown below::

     ___  __
    / _ )/ /__ _    __
   / _  / / _ \ |/|/ /
  /____/_/\___/__,__/  ver: 0.6

  blow [blow_simple_cluster] $ 

Before launching the cluster you may verify its configuration by entering the ``conf`` command on the *Blow* prompt.
Something similar to example shown below will appear on your screen::

  blow [blow_simple_cluster] $ conf
  cluster: blow_simple_cluster
  user-name: your-user-name
  private-key: ./id_rsa
  public-key: ./id_rsa.pub
  access-key: AKIAIF3TUNLSJYG5UWQQ
  region-id: us-east-1
  zone-id: us-east-1b
  image-id: ami-e565ba8c
  instance-type: t1.micro
  size: 5

When ready, launch the cluster by entering the command ``start``::


  blow [blow_simple_cluster] $ start
  
  
It will take a few minutes to start the virtual machines, configure them and install the SGE daemons.
When it is finished something similar to the following output will appear on your screen::

  blow [blow_simple_cluster] $ start
  ~ Creating cluster: blow_simple_cluster
  ~ Creating the 'master' node
  ~ Creating 4 worker node(s)
  ~ Configuring hosts file
  ~ Configuring NFS file system
  ~ Configuring NFS file system
  ~ Configuring OpenGridEngine (SGE)
  blow [blow_simple_cluster] $ 


.. attention::
  If the following message is displayed:

  ``WARN: Disabling high-strength ciphers: cipher strengths apparently limited by JCE policy``

  you will need to install the *Java Cryptography Extension (JCE)* for high-strength ciphers.
  This is not included by default due to US export restrictions. This is available in the `Java download`_ at
  the bottom of the page.

.. _`Java download`: http://www.oracle.com/technetwork/java/javase/downloads/index.html


4. Access the remote master node
--------------------------------

Use the command ``listnodes`` on the *Blow* prompt to get the list of all running nodes in the cluster.
A list similar to the one shown below will appear on your screen::

  blow [blow_simple_cluster] $ listnodes 
  i-ddd162bb;   23.20.217.171; RUNNING; blow_simple_cluster; master
  i-5fd76439;     23.22.43.58; RUNNING; blow_simple_cluster; worker
  i-5dd7643b;     23.22.63.20; RUNNING; blow_simple_cluster; worker
  i-5bd7643d;    23.20.28.196; RUNNING; blow_simple_cluster; worker
  i-59d7643f;    23.20.152.41; RUNNING; blow_simple_cluster; worker


Any node is accessible using an SSH client. *Blow* comes with an integrated SSH client.
To connect to a remote node on the prompt just enter the ``ssh`` command followed by the IP 
address of the node you want to access::

  ssh 23.20.217.171

.. attention::
  The integrated SSH client automatically manages access credentials. Using a different
  SSH client you will need to specify the user name and the identity file (the private key).
  
When connected to the remote node, you may want to verify that the *SGE* scheduler has been 
installed correctly. At the shell prompt of the remote system enter the command ``qhost``.
It should print a list similar to the one shown below::

  [domU-12-31-38-04-10-03 ~]$ qhost
  HOSTNAME                ARCH         NCPU  LOAD  MEMTOT  MEMUSE  SWAPTO  SWAPUS
  -------------------------------------------------------------------------------
  global                  -               -     -       -       -       -       -
  domU-12-31-38-04-10-03  linux-x64       1  0.03  595.4M   49.8M     0.0     0.0
  domU-12-31-38-07-4E-06  linux-x64       1  0.04  595.4M   42.8M     0.0     0.0
  ip-10-122-83-78         linux-x64       1  0.51  595.4M   50.8M     0.0     0.0
  ip-10-122-98-108        linux-x64       1  0.03  595.4M   42.9M     0.0     0.0
  ip-10-124-215-153       linux-x64       1  0.03  595.4M   42.8M     0.0     0.0
  

  
5. Run a simple job and terminate the cluster  
---------------------------------------------

Move to the ``/scratch`` folder, create a job script and submit it to the *SGE* for execution.
For the sake of this tutorial, you could run these commands::

  cd /scratch 
  echo "echo Hello world!" > test.sh
  qsub -cwd -sync y test.sh 
  

When the job has been executed by the *SGE*, your will find the following content in the
current directory::

  $ ls -la 
  total 16
  drwxr-xr-x  2 ec2-user wheel 4096 May 11 14:15 .
  dr-xr-xr-x 26 root     root  4096 May 11 13:59 ..
  -rw-r--r--  1 ec2-user wheel   19 May 11 14:14 test.sh
  -rw-r--r--  1 ec2-user wheel    0 May 11 14:15 test.sh.e1
  -rw-r--r--  1 ec2-user wheel   97 May 11 14:15 test.sh.o1

6. Terminate the cluster session
--------------------------------

When you have done this, don't forget to shutdown the cluster and all the running instances.

Log out from the remote node using the ``exit`` command and stop the cluster, by entering
the command ``terminate`` on the *Blow* prompt.